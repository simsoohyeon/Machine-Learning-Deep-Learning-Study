## 7. 앙상블 학습과 랜덤 포레스트 
### 7.1 투표 기반 분류기 (1)
```
- 앙상블 학습
: 일련의 예측기(분류나 회귀모델)로부터 예측을 수집하면 가장 좋은 모델 하나보다 더 좋은 예측을 얻을 수 있을 것임
랜덤 포레스트는 결정 트리의 앙상블

- 투표 기반 분류기
: 정확도가 80%이상인 분류기를 여러 개 훈련 시켰다고 가정
로지스틱 회귀 분류기, SVM 분류기, 랜덤 포레스트 분류기, K-최근접 이웃 분류기 등

- 직접 투표 분류기 hard voting
: 강한 학습기, 약한 학습기
```
### 7.1 투표 기반 분류기 (4)
```
from sklearn.datasets import make_moons
-> 모듈에서 make_moons 함수 불러움, 이 함수는 두 개의 반달 모양 데이터 포인트를 생성하는데 사용

from sklearn.ensemble import RandomForestClassifier, VotingClassifier
-> 모듈에서 랜덤 포레스트 분류기와 여러 모델의 예측을 결합하는 앙상블 분류기 클래스 불러옴

from sklearn.linear_model import LogisticRegression
-> 모듈에서 로지스틱 회귀 분류기 만드는 클래스 불러옴
from sklearn.model_selection import train_test_split
-> 모듈에서 데이터셋을 학습 세트와 테스트 세트로 분할하는 함수 불러옴

from sklearn.svm import SVC
-> 모듈에서 svc 클래스 불러옴, 서포트 벡터머신 분류기를 만드는데 사용 

X, y = make_moons(n_samples=500, noise=0.30, random_state=42)
-> make_moons 함수 사용하여 500개의 샘플과 약간의 잡음을 가진 반달모양의 데이터셋 생성
x는 특성들 features 이고 y는 타겟 target 레이블이다

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
-> 데이터를 학습 세트와 테스트 세트로 분할한다

voting_clf = VotingClassifier(
    estimators=[
        ('lr', LogisticRegression(random_state=42)),
        ('rf', RandomForestClassifier(random_state=42)),
        ('svc', SVC(random_state=42))
    ]
)
-> VotingClassifier를 생성하고, 세 개의 분류기를 앙상블로 사용한다
lr : 로지스틱 회귀 분류기, rf : 랜덤 포레스트 분류기, svc: 서포트 벡터머신 분류기

voting_clf.fit(X_train, y_train)
-> voting_clf 앙상블 분류기를 학습세트 X_train과 y_train에 맞춰 학습시킴

<결론>
이 코드는 세 가지 다른 머신러닝 모델 로지스틱 회귀, 랜덤 포레스트, 서포트 벡터머신을 결합한
앙상블 모델을 생성하여 학습 데이터를 기반으로 학습시킨다 앙상블 모델은 개별 모델들의 예측을
결합하여 더 강력하고 일반화된 예측 성능을 제공할 수 있게 된다 각 모델은 다른 알고리즘을 사용하여
학습하므로, 서로 다른 모델들의 강점들을 결합하여 더 나은 성능을 낼 수 있다
```
### 7.1 투표 기반 분류기 (5)
```
<테스트 세트에서 훈련된 각 분류기의 정확도 확인>

for name, clf in voting_clf.named_estimators_.items():
    print(name, "=", clf.score(X_test, y_test))
-> voting_clf 앙상블 모델의 각 개별 분류기의 이름과 해당 분류기의 테스트 세트에서의 정확도 출력
-> voting_clf.named_estimators.items() 통해 각 분류기의 이름과 객체 가져옴
clf.score(X_test, y_test) 호출하여 테스트 세트에서의 각 분류기의 정확도를 계산하고 출력 
```
```
<투표 기반 분류기의 predict() 메서드 호출하여 직접 투표 수행>
voting_clf.predict(X_test[:1])
-> voting_clf 앙상블 모델 사용하여 테스트 세트의 첫 번째 샘플에 대해 예측 수행
-> 출력은 예측된 클래스 레이블의 배열

array([1]) : 앙상블 모델이 테스트 세트의 첫 번째 샘플을 클래스 1로 예측

[clf.predict(X_test[:1]) for clf in voting_clf.estimators_]
-> 각 개별 분류기에서듸 테스트 세트의 첫 번째 샘플에 대해 예측을 수행
voting_clf.estimators_ 사용하여 각 분류기 객체를 가져옴
각 분류기의 predict() 메서드 호출하여 예측을 수행하고 결과를 리스트로 반환

[array([1]), array([1]), array([0])]는 각 분류기의 예측 결과로,
로지스틱 회귀, 랜덤 포레스트는 클래스 1을 예측, svc 클래스는 0을 예측

voting_clf.score(X_test, y_test)
-> voting_clf 앙상블 모델의 테스트 세트에서의 정확도를 계산하고 출력
score() 메소드는 주어진 데이터와 레이블에 대한 정확도를 반환
```


### 7.2 배깅과 페이스팅 (1)
```
- 배깅 bagging, bootstrap aggregating 의 줄임말
: 훈련 세트에서 중복을 허용하여 샘플링하는 방식
- 페이스팅 pasting
: 중복을 허용하지 않고 샘플링하는 방식
```
### 7.2 배깅과 페이스팅 (2)
```
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
-> 앙상블 학습의 한 방법인 배깅 분류기 제공, 여러 개의 학습기를 독립적으로 훈련시켜 그 예측을 결합
-> 결정 트리 분류기 제공, 개별 트리 학습기로 사용

bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,
                            max_samples=100, n_jobs=-1, random_state=42)
-> BaggingClassifier 객체 생성, DecisionTreeClassifier() 배깅 앙상블에서 사용할 기본 학습기로
결정 트리 분류기를 지정, 500개의 결정 트리 학습기를 사용하여 앙상블을 구성,
각 기본 학습기는 100개의 샘플을 사용하여 학습, 이 샘플들은 원래 훈련 데이터셋에서 무작위로 선택
n_jobs=-1 모든 가용 CPU 코어를 사용하여 병렬로 학습 -> 모델의 학습 속도를 높여줌

bag_clf.fit(X_train, y_train)
-> BaggingClassifier 객체를 학습 세트에 맞춰서 학습시킴
fit 메소드는 배깅 앙상블 모델을 구성하는 500개의 결정트리 학습기를 각각 무작위로
선택된 100개의 샘플을 사용하여 학습시킴
```
### 7.2 배깅과 페이스팅 (3)
![image](https://github.com/simsoohyeon/Machine-Learning-Deep-Learning-Study/assets/127268889/83e895d7-3801-43ac-83f0-24ba3ce9040f)
```
단일 결정 트리의 결정 경계 vs 500개의 트리를 사용한 배깅 앙상블의 결정 경계 비교
- 왼쪽 그래프, 단일 경정 트리
결정 경계: 결정 트리가 학습한 데이터의 따라 매우 세밀하고 복잡한 경계 형성
트리가 과적합이 된 것으로 보임, 이는 데이터의 잡음과 세부적인 패턴을 과하게 학습한 결과
특징: 데이터의 포인트, 점과 사각형이 있는 곳에서 경계가 복잡하게 구불구불함
새로운 데이터에 대한 예측 성능이 낮을 수 있음

- 오른쪽 그래프, 배깅을 사용한 결정 트리
결정 경계: 여러 개의 결정 트리를 결합한 앙상블 모델의 경계
각 트리의 예측을 결합하여 더 부드럽고 일반화된 경계 형성
단일 트리에 비해 더 단순하고 덜 복잡한 경계 가지고 있음
특징: 결정 경계가 더 부드럽고 안정적이며 과적합을 줄임
다양한 트리의 예측을 결합하므로써 데이터의 잡음을 덜 민감하게 반응함
새로운 데이터에 대한 예측 성능이 더 높을 가능성이 있음

<결론>
- 단일 결정 트리는 데이터의 세부적인 패턴과 잡음을 모두 학습하여 과적합의 위험이 크다
- 배깅을 사용한 앙상블 모델은 여러 트리의 예측을 결합하여 더 일반화된 예측 제공
이는 모델이 과적합을 피하고 새로운 데이터에 대해 더 나은 성능을 발휘하도록 도움
앙상블 기법인 배깅을 통해 개별 모델의 단점을 보완하고 더 강력하고 안정적인 모델을 만듦
```
### 7.2 배깅과 페이스팅 (4)
```
< OOB 평가 설명 >
BaggingClassifier는 기본값을 중복으로 허용하여 (bootstrap=True) 훈련세트의 크기만큼
샘플을 선택함, 이는 평균적으로 각 예측기에 훈련 샘플의 약 63%정도만 샘플링됨
OOB (Out of Bag) 샘플은 선택되지 않은 나머지 37% 샘플을 말함

bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,
                            oob_score=True, n_jobs=-1, random_state=42)
-> 배깅 앙상블에서 사용할 기본 학습기로 결정 트리 분류기 지정,
n_estimators=500 500개의 결정 트리 학습기를 사용하여 앙상블을 구성,
oob_score=True로 지정하면 OOB 평가 활성화, 샘플을 사용하여 훈련이 끝난 후 자동으로 평가

bag_clf.fit(X_train, y_train)
-> BaggingClassifier 객체를 학습 세트 X_train과 y_train에 맞춰 학습
fit 메서드는 배깅 앙상블 모델을 구성하는 500개의 결정 트리 학습기를
각각 무작위로 선택된 샘플 사용하여 학습

bag_clf.oob_score_
-> OOB 샘플 사용하여 계산된 모델의 성능 점수 출력
obb_score_ 속성은 OOB 평가를 통해 계산된 모델의 정확도 나타냄


<요약>
이 코드는 배깅 앙상블을 사용하여 500개의 결정 트리 분류기를
학습시키고, OOB 평가를 통해 모델의 성능을 자동으로 평가합니다.
OOB 샘플은 모델의 성능을 검증하기 위해 사용되며, 이는 별도의
검증 세트를 사용하지 않고도 모델의 일반화 성능을 평가할 수 있는 방법입니다.
oob_score_ 속성은 훈련된 모델의 OOB 평가 정확도를 반환합니다.
이 예제에서는 0.896의 OOB 정확도를 얻었습니다.
```
### 7.2 배깅과 페이스팅 (5)
```
- OOB 평가 결과 확인
from sklearn.metrics import accuracy_score
-> 모듈에서 accuracy_score 함수 불러옴, 이 함수는 분류 모델의 정확도를 계산하는데 사용

y_pred = bag_clf.predict(X_test)
-> 학습된 배깅 분류기 bag_clf 를 사용하여 테스트 세트 X_test에 대한 예측 수행
predict 메소드는 입력 데이터에 대해 예측된 클래스 레이블 반환,
y_pred는 예측된 클래스 레이블  저장

accuracy_score(y_test, y_pred)
-> 테스트 세트 y_test와 예측된 클래스 레이블 y_pred를 사용하여 모델의 정확도 계산
accuracy_score 함수는 두 배열을 비교하여 정확도를 계산하고 그 결과를 반환
=> 모델의 정확도는 약 91.2%

- OOB 샘플에 대한 결정 함수의 값도 oob_decision_function_ 변수에서 확인
bag_clf.oob_decision_function_[:3] # 처음 3개의 샘플에 대한 확률
-> 학습된 배깅 분류기 bag_clf의 oob_decision_function 속성을 확인
이 속성은 OOB 샘플에 대한 결정 함수 값을 포함
[:3]은 처음 세 개의 샘플에 대해나 결정 함수의 값을 확인하는 것
=> 첫 번째 샘플 클래스 0에 속할 확률 32 클래스 1에 속할 확률 67
두 번째 샘플 클래스 0에 속할 확률 33 클래스 1에 속할 확률 66
세 번째 샘플 클래스 0에 속할 확률 100 클래스 1에 속할 확률 0

<요약>
이 코드는 배깅 분류기의 OOB 평가 결과와 테스트 세트에 대한 예측 결과를 확인
accurary_score 함수를 사용하여 테스트 세트의 정확도를 계산, 91%의 정확도 얻음
oob_decision_function_ 속성을 통해 OOB 샘플에 대한 각 클래스의 확률 값 확인
모델이 각 샘플에 대해 어떤 확률로 클래스를 예측했는지 보여줌 
```
### 7.3 랜덤 패치와 랜덤 서브스페이스
```
- 랜덤 패치 방식 random patches method
: 훈련 특성과 샘플을 모두 샘플링
모델의 다양성이 증가해 과적합을 줄일 수 있음
데이터의 하위 집합을 사용하기 때문에 학습 속도 증가가

- 랜덤 서브스페이스 방식 random subspaces method
: 훈련 샘플을 모두 사용 bootstrap = False 이고 max_samples=1.0 설정
특성을 샘플링 bootstrap_features=True로 설정, max_features는 1.0보다 작게 설정
모든 샘플을 다 사용하므로 데이터의 중요한 정보를 더 많이 포함하게 됨
특성 공간의 다양성을 높여 모델의 일반화 성능을 향상시킴 

이 방식은 특성 공간의 일부만의 사용하여 학습기를 훈련시키기 때문에,
특성 샘플링 모델은 더 다양한 예측기를 만들 수 있으며,
이는 편향을 늘리는 대신 분산을 낮추어 모델의 안정성을 높임

<결론>
랜덤 패치방식과 랜덤 서브스페이스 방식은 모두 데이터 샘플링을 통해 모델의 다양성을
높이고, 과적합을 줄이며 일반화 성능을 향상시키는데 유용함
랜덤 패치 방식은 특성과 샘플을 모두 샘플링하는 반면, 랜덤 서브스페이스 방식은
샘플은 모두 사용하고 특성만 샘플링한다
이러한 샘플링 방법은 앙상블 학습에서 모델의 성능을 향상시키는데 중요한 역
```
### 7.4 랜덤 포레스트 (1)

#### 랜덤 포레스트 분류기
```
from sklearn.ensemble import RandomForestClassifier
-> 모듈에서 RandomForestClassifier 클래스 불러옴, 랜덤포레스트 분류기 제공

rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)
-> RamdomForestClassifer 객체 생성, 500개의 결정 트리 사용하여 앙상블 구성,
각 결정 트리의 최대 리프 노드 수 16개로 제한

rnd_clf.fit(X_train, y_train)
-> 학습 세트 X_train과 y_train을 사용하여 랜덤 포레스트 분류기 학습
fit 메소드는 모델을 데이터에 맞춰 학습시킴

y_pred_rf = rnd_clf.predict(X_test)
-> 학습된 랜덤 포레스트 분류기를 사용하여 X_test에 대한 예측 수행
predict 메소드는 입력 데이터에 대해 예측된 클래스 레이블을 반환
y_pred_rf는 예측된 클래스 레이블 저장 
```
#### 배깅 분류기
```
from sklearn.ensemble import BaggingClassifier
-> 모듈에서 BaggingClassifier 클래스 불러옴, 배깅 분류기 제공

bag_clf = BaggingClassifier(
    DecisionTreeClassifier(max_features="sqrt", max_leaf_nodes=16),
    n_estimators=500, n_jobs=-1, random_state=42)
-> BaggingClassifier 객체 생성, 배깅 앙상블에서 사용할 기본 학습기로 결정트리 분류기
sqrt는 각 결정 트리가 학습할 대 사용할 특성의 최대 수를 특성 수의 제곱근,
각 결정 트리의  최대 리프 노드 수를 16으로 제한, 500개의 결정 트리 학습시 사용
```
#### 요약
```
첫 번째는 랜덤 포레스트 분류기를 생성하고 학습시키고 테스트 세트에 대한 예측 수행
두 번째는 배깅 분류기 생성, 배깅 분류기는 결정 트리 분류기를 사용하여
앙상블을 구성하고, 여러 학습기를 병렬로 학습시키기 위해 모든 CPU 코어를 사용

두 모델 모두 앙상블 기법을 사용하여 더 강력하고 일반화된 모델을 만드는데 도움 줌
랜덤 포레스트는 여러 무작위 결정 트리를 학습시키고 배깅은 여러 학습기의 예측을 결
```
### 7.4 랜덤 포레스트(2)
```
엑스트라 트리: 익스트림 랜덤 트리 extremely randomized tree 앙상블
또는 줄여서 엑스트라 트리 extra-tree
-> 극단적으로 랜덤한 트리의 랜덤 포레스트, 사이킷런의 ExtraTreesClassifier 사용 
```
### 7.4 랜덤포레스트 (3)
```
- 랜덤포레스트의 또 다른 장점은 특성의 상대적 중요도를 측정하기 쉽다는 점
- 훈련이 끝난 뒤 특성마다 자동으로 이 점수를 계산하고 중요도의 합이 1이 되도록 결과값 정규화
(이 값은 feature_importances_ 변수에 저장되어 있음)
- iris 데이터셋에 RandomForestClassifier를 훈련시키고 각 특성의 중요도를 출력
```
```
from sklearn.datasets import load_iris
-> 모듈에서 load_iris 함수 불러옴, 이 함수는 붓꽃 데이터를 로드하는데 사용

iris = load_iris(as_frame=True)
-> 함수를 호출하여 붓꽃 데이터 로드함, as_frame=True 설정 통해 데이터가 pandas DF 형식으로 반환
iris 변수는 데이터셋을 포함하는 객체로 data와 target 속성 포함

rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)
-> RandomForestClassifier 객체 생성, 500개의 결정 트리 사용하여 앙상블 구성

rnd_clf.fit(iris.data, iris.target)
-> 붓꽃 데이터 특성 iris.data와 타겟값 iris.target을 사용해 랜덤포레스트 분류기 학습
fit 메소드는 모델을 데이터에 맞춰 학습시킴

for score, name in zip(rnd_clf.feature_importances_, iris.data.columns):
    print(round(score, 2), name)
-> 랜덤 포레스트 모델의 특성 중요도 feature_importances_를 iris.data.columns와 함께 순회하며 출력
zip 함수는 두 개의 리스트 rnd_clf.feature_importances_와 iris.data.columns 묶어줌
round(score,2)는 특성 중요도를 소수점 둘째 자리까지 반올림
각 특성의 중요도와 특성 이름 출
```
#### 요약
```
붓꽃 데이터셋을 로드하고 랜덤 포레스트 분류기를 사용하여 학습시킨 후, 각 특성의 중요도 계산
feature_importances_ 속성은 모델이 학습 과정에서 각 특성의 중요도를 나타내는 값
이 값은 모델이 예측을 위해 해당 특성을 얼마나 자주 사용했는지와 관련이 있음
출력 결과에서 petal length, petal width가 sepal length, sepal width보다 더 중요한 특
```
### 7.4 랜덤포레스트 (4)
![image](https://github.com/simsoohyeon/Machine-Learning-Deep-Learning-Study/assets/127268889/d0491e57-69df-4985-9346-2a07da4523a3)
```
위의 이미지는 mnist 데이터셋에서 랜덤 포레스트 분류기를 훈련시킨 후 각 픽셀의 중요도를 시각화한 것
mnist 데이터는 손글씨 숫자 이미지로, 각 이미지는 28*28 픽셀의 흑백 이미지

 색상맵: 오른쪽의 색상막대는 각 픽셀의 중요도로 노란색에 가까울수록 매우 중요한 역할,
검은색일 수록 분류에 덜 중요한 역할임

중요도 시각화: 이미지 중앙의 밝은 영역은 랜덤 포레스트 모델이 숫자를 분류할 때
중요한 픽셀을 나타냄, 어두운 영역은 덜 중요한 픽셀
=> 이는 숫자의 형태가 있는 위치와 일치함 숫자의 주요 부분, 숫자모양을 결정하는 부분이
이 모델의 분류에 중요한 역할임 

<결론>
- 랜덤 포레스트 분류기는 mnist 데이터셋에서 숫자를 분류할 때 특정 픽셀에 더 큰 중요도를 부여함
이는 일반적으로 숫자의 형태를 형성하는 중심 부분
- 시각화는 이런 중요도를 직관적으로 보여주며, 모델이 분류를 수행할 때 주목하는 영역을 명확하게 이해
=> 이런 분석은 모델의 성능을 개선하거나 해석 가능성을 높이는데 중요함
중요도가 높은 픽셀을 더 잘 처리하거나 데이터 전처리를 통해 중요도가 낮은 픽셀의 영향 줄임임
```

### 7.5 부스팅 (1)
```
부스팅: 원래는 가설 부스팅
약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법
가장 인기있는 부스팅 방법은 AdaBoost, adaptive boosting 에이다 부스트와 그레이디언트 부스팅
```
### 7.5 부스팅 (2,3)
```
AdaBoost: 이전 모델이 과소적합했던 훈런 샘플의 가중치를 더 높임
샘플의 가중치를 업데이트하면서 순차적으로 학습하는 AdaBoost
- moons 데이터셋에서 훈련시킨 다섯 개의 연속된 예측기의 결정 경계
이 모델은 규제를 강하게 한 RBF 커널 SVM 분류기
```
![image](https://github.com/simsoohyeon/Machine-Learning-Deep-Learning-Study/assets/127268889/30c64cf3-6270-42c0-b12f-76d4a361b547)
```
왼쪽 그래프 학습률 = 1
- 모델은 한 번에 큰 보폭으로 학습
- 결정 경계가 매우 복잡하고 데이터 포인트를 따라 구불구불하게 형성
- 이는 모델이 훈련 데이터에 과적합이 된 상태
- 복잡한 결정 경계는 훈련 데이터의 잡음까지 학습하여 새로운 데이터에 대한 일반화 성능 낮음

오른쪽 그래프 학습률 = 0.5
- 모델은 더 작은 보폭으로 학습
- 결정 경계가 덜 복잡해 데이터의 주요 패턴을 더 잘 포착함

학습률은 모델의 학습속도와 결정 경계의 복잡도에 영향을 미침 -> 적절한 학습률 선택
너무 높으면 모델이 과적합, 너무 낮으면 학습이 느리고 충분한 경계 형성 X
```
### 7.6 스태킹 (1,2,3)
```
스태킹: 블렌더 또는 메타학습기
블렌더가 학습되면 기본 예측기는 전체 원본 훈련 세트로 마지막에 한 번 더 재훈련

여러 가지 블렌더 (선형 회귀 블렌더, 랜덤 포레스트 회귀 사용하는 블렌더)를 훈련하여
전체 블렌더 계층을 얻은 다음 그 위에 다른 블렌더를 추가하여 최종 예측을 생성
```
### 7.6 스테킹 (4)
```
from sklearn.ensemble import StackingClassifier
-> 모듈에서 StackingClassifier 클래스 불러옴, 이 클래스는 스태킹 앙상블 구현하는데 사용

stacking_clf = StackingClassifier(
    estimators=[
        ('lr', LogisticRegression(random_state=42)),
        ('rf', RandomForestClassifier(random_state=42)),
        ('svc', SVC(probability=True, random_state=42))
    ],
    final_estimator=RandomForestClassifier(random_state=43),
    cv=5  # 교차 검증 폴드 개수
)
-> StackingClassifier 객체 생성,
estimators 스태킹 앙상블에 포함된 기저(베이스모델) 모델 정의,
각 모델은 튜플 형식으로 (이름, 모델) 형태로 지정
('lr', LogisticRegression) 로지스틱 회귀 모델
('rf', RandomForestClassifier) 랜덤 포레스트 모델
('svc', SVC(probability=True)) 확률 출력이 가능한 SVM 모델
final_estimator: 기저 모델들의 예측을 결합하여 최종 예측을 수행할 메타 모델 정의
RandomForestClassifier: 메타 모델로 사용할 랜덤 포레스트 모델
cv=5 : 5-폴드 교차 검증을 사용하여 기저 모델들의 예측 생

stacking_clf.fit(X_train, y_train)
-> StackingClassifier 객체를 학습 세트 X_train과 y_train에 맞춰 학습
fit 메소드는 기저 모델들을 학습시키고, 각 모델의 예측을 기반으로 메타 모델 학습
cv=5 설정으로 인해, 5-폴드 교차 검증을 사용하여 각 기저 모델들의 예측을
생성하고 이를 메타 모델의 입력으로 사용함 
```
#### 전체적인 흐름
```
1. 기저 모델 학습
- 주어진 학습 데이터로 기저 모델들은 학습
- 교차 검증을 통해 각 모델의 예측 결과 생성
2. 메타 모델 학습
- 기저 모델들의 예측 결과를 입력으로 받아 메타 모델을 학습
3. 최종 예측
- 테스트 데이터에 대해 기저 기저 모델들이 예측을 수행하고,
이를 메타 모델에 입력해 최종 예측 수행
```
## 실습 1

## 실습 2






